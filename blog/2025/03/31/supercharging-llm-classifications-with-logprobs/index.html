
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Turn your LLM into a precision instrument for classification – no fine-tuning required. This post shows how to go beyond simple "yes/no" answers and unlock soft classification using logprobs. You'll learn how to extract class probabilities in a single call, tune your classifier for optimal performance, and make your LLM behave more like a proper ML model. Perfect for anyone building smarter, more flexible AI applications.">
      
      
      
        <link rel="canonical" href="http://arcturus-labs.com/blog/2025/03/31/supercharging-llm-classifications-with-logprobs/">
      
      
        <link rel="prev" href="../visual-reasoning-is-coming-soon/">
      
      
        <link rel="next" href="../../../06/17/recipes--a-pattern-for-common-code-transformations/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../../../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../../../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../../../../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>Supercharging LLM Classifications with Logprobs - Arcturus Labs</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/custom.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-9ZGCYE3982"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-9ZGCYE3982",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-9ZGCYE3982",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  
  
  <meta property="og:title" content="Supercharging LLM Classifications with Logprobs">
  <meta property="og:description" content="Turn your LLM into a precision instrument for classification – no fine-tuning required. This post shows how to go beyond simple "yes/no" answers and unlock soft classification using logprobs. You'll learn how to extract class probabilities in a single call, tune your classifier for optimal performance, and make your LLM behave more like a proper ML model. Perfect for anyone building smarter, more flexible AI applications.">
  <meta property="og:image" content="http://arcturus-labs.com/blog/assets/superpower_llm_classifications_with_logprobs/top_image.png">
  <meta property="og:type" content="article">
  <meta property="og:url" content="http://arcturus-labs.com/blog/2025/03/31/supercharging-llm-classifications-with-logprobs/">
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Supercharging LLM Classifications with Logprobs">
  <meta name="twitter:description" content="Turn your LLM into a precision instrument for classification – no fine-tuning required. This post shows how to go beyond simple "yes/no" answers and unlock soft classification using logprobs. You'll learn how to extract class probabilities in a single call, tune your classifier for optimal performance, and make your LLM behave more like a proper ML model. Perfect for anyone building smarter, more flexible AI applications.">
  <meta name="twitter:image" content="http://arcturus-labs.com/blog/assets/superpower_llm_classifications_with_logprobs/top_image.png">
  

  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#building-the-hard-llm-classifier" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Arcturus Labs" class="md-header__button md-logo" aria-label="Arcturus Labs" data-md-component="logo">
      
  <img src="../../../../../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Arcturus Labs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Supercharging LLM Classifications with Logprobs
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Arcturus Labs" class="md-nav__button md-logo" aria-label="Arcturus Labs" data-md-component="logo">
      
  <img src="../../../../../assets/images/logo.png" alt="logo">

    </a>
    Arcturus Labs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blog
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      <a href="../../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Blog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/agentic-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agentic AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/automation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/coding-patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Coding Patterns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/development-methodology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Development Methodology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/multimodal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/prompt-engineering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/reasoning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reasoning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/retrieval/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Retrieval
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/user-experience/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    User Experience
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/vibe-coding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vibe Coding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../contact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contact
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#building-the-hard-llm-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Building the "Hard" LLM Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turning-a-hard-classifier-into-a-soft-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Turning a "Hard" Classifier into a "Soft" Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-your-own-classifier" class="md-nav__link">
    <span class="md-ellipsis">
      Making Your Own Classifier
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hey-and-if-you-liked-this-post-then-maybe-we-should-be-friends" class="md-nav__link">
    <span class="md-ellipsis">
      Hey, and if you liked this post, then maybe we should be friends!
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2025-03-31 00:00:00" class="md-ellipsis">March 31, 2025</time>
                      </div>
                    </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg>
                          <span class="md-ellipsis">
                            in
                            
                              <a href="../../../../category/classification/">Classification</a></span>
                        </div>
                      </li>
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              8 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        


  <h1>Supercharging LLM Classifications with Logprobs</h1>

<p>I was just reading the classification chapter of Jay Alammar and Maarten Grootendorst's excellent book <a href="https://amzn.to/4lfynRy">Hands-On Large Language Models</a>. I felt inspired to extend their work and show yet another cool trick you can do with LLM-based text classification. In their work they demonstrated how an LLM can be used as a "hard classifier" to determine the sentiment of movie reviews. By "hard" I mean that it gives a concrete answer, "positive" or "negative". However, we can do one better! Using <em>"this one simple trick"</em>™ we can make a "soft" classifier that returns the probabilities of each class rather than a concrete single choice. This makes it possible to <em>tune</em> the classifier – you can set a threshold in the probabilities so that classifications are optimally aligned with a training set.</p>
<p><img align="left" alt="Soft Classification" src="../../../../assets/superpower_llm_classifications_with_logprobs/top_image.png" width="100%" /></p>
<!-- more -->

<div class="admonition note">
<p class="admonition-title">Videos more your cup of tea?</p>
<p>I'm a slow reader - so I often go to YouTube to have ideas beamed directly into my brain. And now you can do the same thing! Watch me summarize this post in just 10 minutes! Outtakes never taken out.</p>
<p><figure markdown="span">
  <iframe width="70%" src="https://www.youtube.com/embed/FN7oaLcIlvk" title="Supercharging LLM Classifications with Logprobs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure></p>
</div>
<h2 id="building-the-hard-llm-classifier">Building the "Hard" LLM Classifier</h2>
<p>To quickly repeat/paraphrase the work of Hands-On Large Language Models, here's how to build a sentiment classifier using an LLM.</p>
<ol>
<li>Create a prompt that explains the task: "Find the sentiment of this movie review."</li>
<li>Add in the text to be classified.</li>
<li>Explain the output format for the classification: "Please say only 'positive' or 'negative' and no other words or explanations."</li>
</ol>
<p>Here's how we could couch this inside of a function:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span>   
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Read the following text and tell me if the sentiment is positive or negative: </span>

<span class="s2">        &gt; </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>

<span class="s2">        Just say &#39;positive&#39; or &#39;negative&#39; (lowercase - no other text - no quotes no words besides positive or negative)&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="p">}]</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</code></pre></div>
<p>Let's use it a couple of times:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">get_sentiment</span><span class="p">(</span><span class="s2">&quot;this sucks&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span> 
<span class="n">negative</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">get_sentiment</span><span class="p">(</span><span class="s2">&quot;it&#39;s awesome&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span>
<span class="n">positive</span>
</code></pre></div>
<p>Perfect.</p>
<p>Let's try one more time:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">get_sentiment</span><span class="p">(</span><span class="s2">&quot;this sucks, it&#39;s awesome&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span>
<span class="n">positive</span>
</code></pre></div>
<p>Positive? Really? I mean, surely there's some nuance to that, right? Let's try it again a few more times – click, click, click – and we get another 2 positives and a negative. So there <em>is</em> nuance. But how can we understand what the nuance is? How can we take advantage of this?</p>
<h2 id="turning-a-hard-classifier-into-a-soft-classifier">Turning a "Hard" Classifier into a "Soft" Classifier</h2>
<p>The solution is obvious, right? If you run the classifier several times, then the ratio would eventually converge to the true value, and we would have our soft classifier. But the problem with this solution is just as obvious – how many times do you have to run the classifier before it converges on the correct solution? The answer... lots. And I ain't got that kind of time or money.</p>
<p>But would you believe that you can get the <em>exact</em> probabilities in a single LLM completion request? You can, but first you need to read cool info box about logprobs.</p>
<div class="admonition note">
<p class="admonition-title">Cool Info Box About Logprobs (or "The Lies We Tell Ourselves")</p>
<p>When an LLM makes a completion, it doesn't just magically come back with the text all at once. That's a lie. Instead, it looks at the prompt and generates a single token, and then this token gets appended to the prompt and the calculation happens all over again. And one token at a time, the completion is calculated.</p>
<p>But this is <em>also</em> a lie. Because the LLM doesn't really come up with the next token. It's actually a 2-step process. First the LLM looks at the prompt, and rather than predicting the next token it <em>actually</em> comes up with a long list of probabilities for every possible next token. For instance, gpt-4o has roughly 100K next tokens – if you prompt it with "Today's weather is" then every possible next token is associated with a probability. Among them will be "sunny", "cloudy", "hot", "cold", "rainy", all with reasonably high probabilities. But there will also be all the other tokens "pickle", "manly", "dance", "even" most with infinitesimally small probabilities. And if you summed up all the probabilities, they would add up to 1.0 – that is, there's a 100% chance that one of these tokens will be the next token - nothing less, nothing more.</p>
<p>There is one more complexity to cover. (Yes, this was another lie.) Each token is actually associated with a "logprob" rather than a probability - that is, the logarithm of the probability rather than the actual probability. Why? It's just easier computationally. It's also no big deal – you can convert from logprobs to probabilities by taking the exponent of the logprob.</p>
<p>Oh... yeah, and all of that was a lie too. If you <em>really</em> want to know what's happening inside the LLM, I recommend you again to <a href="https://amzn.to/4lfynRy">Hands-On Large Language Models</a> – in particular, chapter 3. But my explanation here is sufficient for now.</p>
</div>
<p>With that knowledge in hand, here is how to extend the hard classifier above to make our soft classifier. First you have to follow the exact same steps above to make the hard classifier. But for the request, you ask for the logprobs to be returned. You don't want the probabilities of all ~100K tokens, but 10 or so should be enough. Then, when you get the completion back, you extract the logprob for each of the possible next tokens and convert them into probabilities.</p>
<p>Let's take a look at the implementation:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span>   
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Read the following text and tell me if the sentiment is positive or negative: </span>

<span class="s2">        &gt; </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>

<span class="s2">        Just say &#39;positive&#39; or &#39;negative&#39; (lowercase - no other text - no quotes no words besides positive or negative)&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="p">}]</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
        <span class="n">logprobs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># this instructs the model to return the logprobs for each token returned</span>
        <span class="n">top_logprobs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># this further instructs the model to return the top 10 logprobs, not just the one selected</span>
    <span class="p">)</span>

    <span class="c1"># Extract top logprobs and convert to probabilities</span>
    <span class="n">logprobs_list</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">content</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">top_logprobs</span> <span class="c1"># we only care about the first token in the completion</span>
    <span class="n">token_probs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># item.token is the text of the token - &quot;positive&quot;, &quot;negative&quot;, or something else</span>
        <span class="c1"># math.exp(item.logprob) is the probability of that token</span>
        <span class="n">item</span><span class="o">.</span><span class="n">token</span><span class="p">:</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">logprob</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">logprobs_list</span>
    <span class="p">}</span>

    <span class="c1"># for the sentiment classification, I only care about the probability of &#39;positive&#39; and &#39;negative&#39;</span>
    <span class="c1"># but I&#39;m lumping the probability for all other possible tokens into &quot;other&quot;</span>
    <span class="n">pos_prob</span> <span class="o">=</span> <span class="n">token_probs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">neg_prob</span> <span class="o">=</span> <span class="n">token_probs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">other_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">pos_prob</span> <span class="o">+</span> <span class="n">neg_prob</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;positive&#39;</span><span class="p">:</span> <span class="n">pos_prob</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">:</span> <span class="n">neg_prob</span><span class="p">,</span> <span class="s1">&#39;other&#39;</span><span class="p">:</span> <span class="n">other_prob</span><span class="p">}</span>
</code></pre></div>
<p>To see how it works, let's run this sentiment classifier with the problematic example from above:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">get_sentiment</span><span class="p">(</span><span class="s2">&quot;this sucks - it&#39;s awesome&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span>
<span class="p">{</span>
    <span class="s1">&#39;positive&#39;</span><span class="p">:</span> <span class="mf">0.5621647747752282</span><span class="p">,</span>
    <span class="s1">&#39;negative&#39;</span><span class="p">:</span> <span class="mf">0.4378143668101077</span><span class="p">,</span>
    <span class="s1">&#39;other&#39;</span><span class="p">:</span> <span class="mf">2.085841466414884e-05</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
<p>There's our nuance! Before, we ran the hard classifier 4 times and found that it was positive 75% of the time and negative 25% of the time. But with the hard classifier it would be impossible to have an accurate estimate without running the classification many, many times. But if you have access to the underlying probabilities (and we do!) then you don't have to run the classifier multiple times. You can just look and immediately see what tiny fraction of the time the model would have classified the sentiment as positive vs. negative.</p>
<p>What's more, you can set a threshold for the probability of the classifier and tune its performance to maximize your desired criteria. For example, it would be naive to assume that if the value associated with <code>positive</code> is greater than <code>negative</code>, this implies that the sentiment is positive. There might be some bias in the classifier – but you can tune for it! You can run the soft classifier on a labeled sample of your dataset and adjust the cutoff threshold so that accuracy for your sample is optimized. This might mean that any value for <code>positive</code> that is above, say, 0.47 is counted as being positive.</p>
<h2 id="making-your-own-classifier">Making Your Own Classifier</h2>
<p>If you want to make a similar classifier, then here are some ideas and tips to consider:</p>
<ul>
<li>Sentiment analysis only has 2 options "positive" or "negative", but your implementation could have many more. For instance, you could make a tech support classifier that classifies emails into the portion of the product that is being discussed.</li>
<li>Sentiment analysis requires almost no explanation, but your classifier could incorporate a prompt with considerable explanation and some examples. Maybe you could even employ chain-of-thought or reasoning prior to declaring its final answer.</li>
<li>Notice that in the above implementation I was keeping track of the probability associated with "other" tokens besides "positive" and "negative", this is because ambiguous text can make the classifier jump to a token besides "positive" and "negative", such as "ambiguous". A better classifier would take this into account. There are several options here:<ol>
<li>You can normalize the probabilities so that prob("positive") and prob("negative") sum to 1.0 and ignore the other tokens.</li>
<li>You can listen to what the LLM is trying to tell you – catalog the other tokens being referred to and incorporate them into new classifier with more options.</li>
<li>Add an explicit "none of the above" option.</li>
</ol>
</li>
<li>Whenever you implement a "soft" classifier make sure that each of the classes you select are single tokens. For instance, "positive" and "negative" are tokens, but if "positive" was two tokens "pos" and "itive", then this technique wouldn't work - at least not without some extra considerations. One easy way to get around this is to use numbered options for your classes.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>There are a lot of fun things you can do with logprobs. For instance, when we were working at GitHub, the coauthor on my book, Albert Ziegler, was experimenting with a way to pack the optimum number of few shot examples into a prompt. He did this by measuring the "perplexity" of the text of the Nth example, which is derived from the logprobs of that text.</p>
<p>Unfortunately, not to many frontier models these days actually surface logprobs – to my knowledge, only OpenAI. And I can see why not – full access to logprobs makes it much easier to distill the knowledge of a teacher model into a student model. So even OpenAI has limited access to only output tokens (which means that, you can't do Albert's trick any more!). But if you're using OpenAI or hosting your own open-weights model then building a classifier like this is still a neat tool to have in your belt.</p>
<p>Oh! Shout-out to Jay Alammar and Maarten Grootendorst. If you really want to grok how things work inside the model and learn some neat approaches for using them, then make sure to grab a <a href="https://amzn.to/4lfynRy">copy of their book</a>. It's fantastic!</p>
<hr />
<h3 id="hey-and-if-you-liked-this-post-then-maybe-we-should-be-friends">Hey, and if you liked this post, then maybe we should be friends!</h3>
<ul>
<li>I just wrote a book about Prompt Engineering for LLM Applications. <a href="/#about">Maybe you'd be interested in reading it.</a></li>
<li>Are you stumped on a problem with your own LLM application? <a href="/#contact-blog">Let me hear about it.</a></li>
<li>I'm going to write lots more posts. <a href="/#contact-blog">Subscribe and you'll be the first to know</a>.</li>
</ul>







  
  



  


  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.copy"], "search": "../../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../../../../../assets/scripts/custom.js"></script>
      
    
  </body>
</html>