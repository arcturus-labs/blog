{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker stop es-local-dev kibana-local-dev ; curl -fsSL https://elastic.co/start-local | sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('superheroes.csv')\n",
    "hero_dict = df[['name', 'description']].set_index('name')['description']\n",
    "\n",
    "hero_dict_alt = {\n",
    "    \"Spider-Man\": \"An adolescent scholar affected by an irradiated arachnid\",\n",
    "    \"Batman\": \"A wealthy entrepreneur and humanitarian\",\n",
    "    \"Wonder Woman\": \"A mythical female combatant from a secluded isle\",\n",
    "    \"Iron Man\": \"A brilliant innovator and corporate magnate\",\n",
    "    \"Superman\": \"An extraterrestrial being from a distant celestial body\",\n",
    "    \"Black Panther\": \"Monarch of an imaginary technologically advanced realm\",\n",
    "    \"The Flash\": \"A criminal investigator possessing extraordinary velocity\",\n",
    "    \"Captain America\": \"A mid-20th century enhanced combatant\",\n",
    "    \"Green Lantern\": \"An aviator selected by an intergalactic peacekeeping force\",\n",
    "    \"Thor\": \"A Norse deity commanding atmospheric phenomena\",\n",
    "    \"Hulk\": \"An academic transformed by electromagnetic emissions\",\n",
    "    \"Wolverine\": \"A genetic anomaly with rapid recuperation and metallic appendages\",\n",
    "    \"Black Widow\": \"An expertly trained covert operative\",\n",
    "    \"Doctor Strange\": \"A brain surgeon transformed into a mystical guardian\",\n",
    "    \"Deadpool\": \"A hired gun with rapid cellular regeneration\",\n",
    "    \"Captain Marvel\": \"A former military aviator with extraterrestrial abilities\",\n",
    "    \"Scarlet Witch\": \"A genetic anomaly capable of warping existence\",\n",
    "    \"Ant-Man\": \"A reformed burglar capable of altering his dimensions\",\n",
    "    \"Daredevil\": \"A visually impaired attorney with heightened perception\",\n",
    "    \"Aquaman\": \"The semi-terrestrial sovereign of an underwater civilization\",\n",
    "    \"Green Arrow\": \"A wealthy masked bowman\",\n",
    "    \"Cyborg\": \"A former sportsman transformed into a mechanized defender\",\n",
    "    \"Hawkeye\": \"An expert marksman and ex-carnival entertainer\",\n",
    "    \"Black Canary\": \"A combatant with ultrasonic vocal capabilities\",\n",
    "    \"Vision\": \"A synthetic being crafted by an artificial intelligence, energized by a cosmic gem\",\n",
    "    \"Martian Manhunter\": \"A metamorphosing extraterrestrial from a neighboring planet\",\n",
    "    \"Storm\": \"A genetic anomaly capable of atmospheric manipulation\",\n",
    "    \"Nightwing\": \"The inaugural juvenile assistant who became an autonomous guardian\",\n",
    "    \"Jean Grey\": \"A formidable psychic with telekinetic capabilities\",\n",
    "    \"Shazam\": \"A juvenile who metamorphoses into an adult champion\",\n",
    "    \"Beast\": \"A brilliant academic with feral characteristics\",\n",
    "    \"Batgirl\": \"A technologically adept masked information specialist\",\n",
    "    \"Gambit\": \"A genetic anomaly capable of imbuing objects with kinetic potential\",\n",
    "    \"Green Lantern\": \"A construction professional and ex-military serviceman\",\n",
    "    \"Wasp\": \"A couturier with mass-altering capabilities\",\n",
    "    \"Zatanna\": \"An illusionist with authentic arcane abilities\",\n",
    "    \"Cyclops\": \"The commander of genetic anomalies with ocular energy projection\",\n",
    "    \"Supergirl\": \"A female relative of an extraterrestrial champion\",\n",
    "    \"Falcon\": \"A former aerial rescue specialist with mechanical appendages\",\n",
    "    \"Batwoman\": \"A former armed forces commander turned masked vigilante\",\n",
    "    \"Luke Cage\": \"An individual with impenetrable epidermis and extraordinary vigor\",\n",
    "    \"Starfire\": \"An otherworldly royal with luminous capabilities\",\n",
    "    \"Quicksilver\": \"A genetic anomaly with extraordinary velocity\",\n",
    "    \"Raven\": \"A semi-infernal empath with shadowy capabilities\",\n",
    "    \"Moon Knight\": \"A masked guardian with dissociative identity disorder\",\n",
    "    \"Firestorm\": \"Amalgamated into an atomic-powered champion\",\n",
    "    \"She-Hulk\": \"A legal professional with emerald-hued capabilities\",\n",
    "    \"Atom\": \"An academic capable of reducing to microscopic proportions\",\n",
    "    \"Nova\": \"A member of a cosmic peacekeeping organization\",\n",
    "    \"Plastic Man\": \"A reformed lawbreaker with malleable physiology\",\n",
    "    \"Ghost Rider\": \"A motorcycle daredevil merged with an infernal entity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLADE setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnberryman/.virtualenvs/blog/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "id2token = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marry had a little lamb , it ' s flee ##ce was white as snow\n",
      "['marriage', 'married', 'winter', 'song', 'wedding', 'have', 'sheep', 'whites', 'baby', 'like', 'color', 'wearing', 'film', 'character', 'murder', 'said', 'england', 'gay', 'story', 'horse', 'went', 'gypsy', 'were', 'snowfall', 'chorus', 'clothing', 'dance', 'got', 'the']\n"
     ]
    }
   ],
   "source": [
    "# the equation is explained in the paper\n",
    "# the code is copied from https://www.pinecone.io/learn/splade/#SPLADE-Embeddings \n",
    "def get_splade_embedding(text, num_tokens=50):\n",
    "    # get the tokens\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    # get the splade embedding\n",
    "    output = model(**tokens)\n",
    "    vec = torch.max(\n",
    "        torch.log(\n",
    "            1 + torch.relu(output.logits)\n",
    "        ) * tokens.attention_mask.unsqueeze(-1),\n",
    "    dim=1)[0].squeeze()\n",
    "\n",
    "    # Convert vec to numpy for easier manipulation\n",
    "    vec_np = vec.detach().numpy()\n",
    "\n",
    "    # Get indices of non-zero elements\n",
    "    non_zero_indices = vec_np.nonzero()[0]\n",
    "\n",
    "    # Create a list of (token, value) pairs for non-zero elements, excluding the input tokens\n",
    "    token_value_pairs = [\n",
    "        (id2token[idx], vec_np[idx]) \n",
    "        for idx in non_zero_indices \n",
    "        if idx not in tokens['input_ids'][0]\n",
    "    ]\n",
    "\n",
    "    # Sort by value in descending order\n",
    "    token_value_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    new_tokens = [token for token, value in token_value_pairs[:num_tokens]]\n",
    "        \n",
    "    return new_tokens\n",
    "\n",
    "def get_tokens_as_text(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt').input_ids[0]\n",
    "    return ' '.join([id2token[i] for i in tokens.tolist()][1:-1])\n",
    "\n",
    "    \n",
    "text = \"marry had a little lamb, it's fleece was white as snow\"\n",
    "print(get_tokens_as_text(text))\n",
    "print(get_splade_embedding(text, num_tokens=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hero, description in hero_dict.items():\n",
    "    splade_tokens = get_splade_embedding(hero_dict_alt[hero],10)\n",
    "    splade_tokens_w_hero = get_splade_embedding(hero_dict_alt[hero] + ' ' + hero,10)\n",
    "    # print(hero, '|', description, '|', hero_dict_alt[hero], '|', splade_tokens, '|', splade_tokens_w_hero, \"\\n\")\n",
    "    num_included = 0\n",
    "    for token in splade_tokens:\n",
    "        if token in description:\n",
    "            num_included += 1\n",
    "    # print(f'Number of included tokens: {num_included}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elasticsearch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnberryman/Dropbox/Notebooks/elastic-start-local/elastic-start-local/.env\n",
      "Y9mOHGDA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "# print pwd using python\n",
    "from pathlib import Path\n",
    "\n",
    "# pull in environment variables\n",
    "from dotenv import load_dotenv\n",
    "path = Path.cwd().parent.parent.parent / 'elastic-start-local' / 'elastic-start-local' / '.env'\n",
    "load_dotenv(path, override=True)\n",
    "print(path)\n",
    "print(os.getenv(\"ES_LOCAL_PASSWORD\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'superheroes' deleted successfully.\n",
      "Index 'superheroes' created successfully.\n",
      "Indexed 50 superheroes.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", os.getenv(\"ES_LOCAL_PASSWORD\"))\n",
    ")\n",
    "\n",
    "\n",
    "def index_superheroes(num_tokens=50):\n",
    "    # Create the index with mappings\n",
    "    index_name = \"superheroes\"\n",
    "    mappings = {\n",
    "        \"mappings\": {\n",
    "            \"dynamic\": \"false\",\n",
    "            \"properties\": {\n",
    "                \"description\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"english\",\n",
    "                },\n",
    "                \"splade\": {\n",
    "                    \"type\": \"text\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # delete and recreate the index\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' does not exist.\")\n",
    "\n",
    "    es.indices.create(index=index_name, body=mappings)\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "\n",
    "    df = pd.read_csv('superheroes.csv')\n",
    "    # Index the superheroes\n",
    "    for i, (index, row) in enumerate(df.iterrows(), start=1):\n",
    "        # Combine the index (superhero name) with the row data\n",
    "        full_row = pd.concat([pd.Series({'name': index}), row])\n",
    "        doc = full_row.to_dict()\n",
    "        doc['splade'] = get_splade_embedding(doc['description'], num_tokens)\n",
    "        es.index(index=index_name, id=i, body=doc)\n",
    "\n",
    "    print(f\"Indexed {len(df)} superheroes.\")\n",
    "\n",
    "index_superheroes(num_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Spider-Man',\n",
       "  'true_identity': 'Peter Parker',\n",
       "  'description': ' a high school student bitten by a radioactive spider',\n",
       "  'comics': 'The Amazing Spider-Man',\n",
       "  'publisher': 'Marvel Comics',\n",
       "  'superpowers': 'Web-slinging, superhuman strength, spider-sense',\n",
       "  'splade': ['spiders',\n",
       "   'bite',\n",
       "   'radiation',\n",
       "   'radio',\n",
       "   'students',\n",
       "   'murder',\n",
       "   'bites',\n",
       "   'teen',\n",
       "   'bomb',\n",
       "   'died']},\n",
       " {'name': 'Shazam',\n",
       "  'true_identity': 'Billy Batson',\n",
       "  'description': ' a young boy who transforms into an adult superhero',\n",
       "  'comics': 'Whiz Comics',\n",
       "  'publisher': 'DC Comics',\n",
       "  'superpowers': 'Superhuman strength, flight, lightning manipulation, wisdom of Solomon',\n",
       "  'splade': ['transform',\n",
       "   'transformation',\n",
       "   'hero',\n",
       "   'boys',\n",
       "   'teen',\n",
       "   'adults',\n",
       "   'comics',\n",
       "   'become',\n",
       "   'actor',\n",
       "   'character']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def search_superheroes(description, size, splade):\n",
    "    if splade:\n",
    "        splade_tokens = get_tokens_as_text(description)\n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": description,\n",
    "                                \"fields\": [\"description\"]\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": splade_tokens,\n",
    "                                \"fields\": [\"splade\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": description,\n",
    "                    \"fields\": [\"description\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    query['size'] = size\n",
    "    # print(query)\n",
    "    \n",
    "    response = es.search(index=\"superheroes\", body=query)\n",
    "\n",
    "    hits = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return hits\n",
    "\n",
    "def retrieve_superhero(name):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"name\": name\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index=\"superheroes\", body=query)\n",
    "    if response['hits']['hits']:\n",
    "        return response['hits']['hits'][0]['_source']\n",
    "\n",
    "\n",
    "search_superheroes(\"spider boy\", 3, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black Panther', 'Iron Man', 'Beast']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero = \"Iron Man\"\n",
    "alt_description = hero_dict_alt[hero]\n",
    "search_results = search_superheroes(alt_description, 3, True)\n",
    "result_heroes = [result['name'] for result in search_results]\n",
    "\n",
    "result_heroes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall_at_3(splade):\n",
    "    counter = 0\n",
    "    for hero in hero_dict.keys():\n",
    "        # print(hero)\n",
    "        alt_description = hero_dict_alt[hero]\n",
    "        search_results = search_superheroes(alt_description, 3, splade)\n",
    "        result_heroes = [result['name'] for result in search_results]\n",
    "        if hero in result_heroes:\n",
    "            counter += 1\n",
    "        \n",
    "    return counter / len(hero_dict.keys())\n",
    "\n",
    "recall_at_3(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'superheroes' deleted successfully.\n",
      "Index 'superheroes' created successfully.\n",
      "Indexed 50 superheroes.\n",
      "3: 0.28 -> 0.52\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "index_superheroes(num_tokens=50)\n",
    "time.sleep(2)\n",
    "k = 3\n",
    "print(f'{k}: {recall_at_3(False)} -> {recall_at_3(True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marriage',\n",
       " 'married',\n",
       " 'winter',\n",
       " 'song',\n",
       " 'wedding',\n",
       " 'have',\n",
       " 'sheep',\n",
       " 'whites',\n",
       " 'baby',\n",
       " 'like',\n",
       " 'color',\n",
       " 'wearing',\n",
       " 'film',\n",
       " 'character',\n",
       " 'murder']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_splade_embedding(\"marry had a little lamb, it's fleece was white as snow\", 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
